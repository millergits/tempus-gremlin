---
description: The Onboarding Journey
---
# The Onboarding Journey

â† Back to Index

Role:New ML Scientist (Week 1-2)Goal:Get productiveon Tempus ML infrastructure without
 reading 74 repos worth of documentation.Key Challenge:Tribal knowledge. The "right way" to do
  things is scattered across wikis, Slack threads, and the minds of senior engineers.


The Onboarding Problem
A new hire at Tempus faces:

    â—      74+ repositorieswith varying documentation quality
     â—      No single source of truthfor "How do I train a model?"
      â—      Acronym soup:FTM, TDM, DPL, OFM, TOT, FSDP, ZeRO-3...
       â—      Implicit conventions:Which SHA hash to use, whichbucket to write to, which Slack
                 channel to ask

Average time to first productive experiment:3-4 weeks.

GREMLIN target:3-4 days.




Phase 1: Orientation ("Where Am I?")
Context:Day 1. The scientist has SSH access and alaptop. They've heard terms like "Hypernexus"
 and "Atlas" but don't know what they are or how they connect.


ğŸ›‘ The Old Way


    â— Read the onboarding wiki (last updated 8 months ago).
     â— Ask on Slack: "How do I get started with ML training?"
      â— Get 5 different answers pointing to 5 different repos.


ğŸ‘¾ The GREMLIN Way


Command:Ask for an overview.Action:GREMLIN providesa structured map of the ML
 ecosystem, tailored to the scientist's role.

gremlin > I just joined the ML team. Give me an overview of the ML infrastructure.


[LOG] Welcome to Tempus ML! Let me orient you.



ğŸ—ºï¸ THE TEMPUS ML ECOSYSTEM




You'll work with three main systems:





â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”


â”‚   1. ATLAS (The Registry)                                  â”‚


â”‚      "Where experiments live"                              â”‚


â”‚      - Tracks datasets, models, and runs                   â”‚


â”‚      - Everything has a URI: atlas://datasets/my_cohort    â”‚


â”‚      - Think: MLflow + metadata governance                 â”‚

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤



â”‚   2. HYPERNEXUS (The Compute)                              â”‚


â”‚      "Where training happens"                              â”‚


â”‚      - H200 GPU cluster (up to 512 GPUs)                   â”‚


â”‚      - Submit jobs via Ray                                 â”‚


â”‚      - Think: Your distributed training backend            â”‚

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤



â”‚   3. INFERNO (The Serving)                                 â”‚


â”‚      "Where models go to production"                       â”‚


â”‚      - vLLM-based inference platform                       â”‚


â”‚      - Think: Your deployment target                       â”‚


â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



Your daily
